{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60168256-45de-49cc-a37f-6a2e068a7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from runner import *\n",
    "from net import NeuralNet, NeuralNetCalssifierComparer,\\\n",
    "    NeuralNetCalssifierComparerAuxLoss\n",
    "from utils import report_from, Verbosity, list_to_string,\\\n",
    "    plot_outputs_single_network_arch_from_list\n",
    "\n",
    "verbose = Verbosity.No\n",
    "\n",
    "tensorboard_output = False\n",
    "if tensorboard_output:\n",
    "    os.system('rm -rf ./runs >> /dev/null&')\n",
    "    os.system('tensorboard --logdir=runs --bind_all &')\n",
    "\n",
    "test_rounds = 10\n",
    "input_size_cc = 14 * 14  # MLP_RUNNER2\n",
    "input_size_mlp = 2 * 14 * 14  # MLP_RUNNER\n",
    "lr = 5e-5\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "def do_train_test(hidden_size_list, epochs, filename):\n",
    "    MLP_outputs = {}\n",
    "    MLP_train_losses = {}\n",
    "    MLP_test_losses = {}\n",
    "    MLP_train_accs = {}\n",
    "    MLP_test_accs = {}\n",
    "    for hidden_size in hidden_sizes_list:\n",
    "        MLP_run_output = []\n",
    "        for i in range(test_rounds):\n",
    "            model_mlp = NeuralNet(input_size_mlp, hidden_size,\n",
    "                                  batchnorm_bool=True,\n",
    "                                  dropout_bool=True)  # plain MLP\n",
    "\n",
    "            optimizer_mlp = torch.optim.Adam(model_mlp.parameters(), lr=lr)\n",
    "            criterion_mlp = nn.BCELoss()\n",
    "\n",
    "            MLP = MLPRunner(model_mlp, [criterion_mlp], optimizer_mlp,\n",
    "                            epochs, batch_size,\n",
    "                            name=f'MLP_VANILLA_{i}_{hidden_size}',\n",
    "                            weights=[1.0, 1.0, 1.0],\n",
    "                            writer_bool=tensorboard_output, verbose=verbose)\n",
    "            MLP_run_output.append(MLP.run())\n",
    "            MLP_train_losses[list_to_string(hidden_size)] = MLP.train_loss\n",
    "            MLP_test_losses[list_to_string(hidden_size)] = MLP.test_loss\n",
    "            MLP_train_accs[list_to_string(hidden_size)] = MLP.train_acc\n",
    "            MLP_test_accs[list_to_string(hidden_size)] = MLP.test_acc\n",
    "            MLP_outputs = {\"MLP_train_losses\": MLP_train_losses,\n",
    "                           \"MLP_test_losses\": MLP_test_losses,\n",
    "                           \"MLP_train_accs\": MLP_train_accs,\n",
    "                           \"MLP_test_accs\": MLP_test_accs}\n",
    "        report_from(MLP_run_output, f\"MLP_VANILLA_{hidden_size}\")\n",
    "        # plot_outputs_single_network_arch(MLP_outputs,\n",
    "        #                                  \"Vanilla MLP NNs\",\n",
    "        #                                  \"MLP 196_\")\n",
    "\n",
    "    CC_outputs = {}\n",
    "    CC_train_losses = {}\n",
    "    CC_test_losses = {}\n",
    "    CC_train_accs = {}\n",
    "    CC_test_accs = {}\n",
    "    for hidden_size in hidden_sizes_list:\n",
    "        CC_run_output = []\n",
    "        for i in range(test_rounds):\n",
    "            model_cc = NeuralNetCalssifierComparer(\n",
    "                input_size_cc,\n",
    "                hidden_size,\n",
    "                hidden_sizes_comparer=[80, 80, 20],\n",
    "                batchnorm_classifer_bool=True,\n",
    "                dropout_classifier_bool=True)\n",
    "            optimizer_cc = torch.optim.Adam(model_cc.parameters(), lr=lr)\n",
    "            criterion_cc = nn.BCELoss()\n",
    "\n",
    "            CC = MLPClassifierComparerRunner(\n",
    "                model_cc, [criterion_cc], optimizer_cc,\n",
    "                epochs, batch_size,\n",
    "                name=f'MLP_classifier_comparer_{i}_{hidden_size}',\n",
    "                writer_bool=tensorboard_output, verbose=verbose)\n",
    "            CC_run_output.append(CC.run())\n",
    "            CC_train_losses[list_to_string(hidden_size)] = CC.train_loss\n",
    "            CC_test_losses[list_to_string(hidden_size)] = CC.test_loss\n",
    "            CC_train_accs[list_to_string(hidden_size)] = CC.train_acc\n",
    "            CC_test_accs[list_to_string(hidden_size)] = CC.test_acc\n",
    "            CC_outputs = {\"CC_train_losses\": CC_train_losses,\n",
    "                          \"CC_test_losses\": CC_test_losses,\n",
    "                          \"CC_train_accs\": CC_train_accs,\n",
    "                          \"CC_test_accs\": CC_test_accs}\n",
    "        report_from(CC_run_output, f\"MLP_classifier_comparer_{hidden_size}\")\n",
    "\n",
    "\n",
    "    CC_AUX_outputs = {}\n",
    "    CC_AUX_train_losses = {}\n",
    "    CC_AUX_test_losses = {}\n",
    "    CC_AUX_train_accs = {}\n",
    "    CC_AUX_test_accs = {}\n",
    "    for hidden_size in hidden_sizes_list:\n",
    "        CC_aux_run_output = []\n",
    "        for i in range(test_rounds):\n",
    "            model_cc_aux = NeuralNetCalssifierComparerAuxLoss(\n",
    "                input_size_cc,\n",
    "                hidden_size,\n",
    "                hidden_sizes_comparer=[80, 80, 20],\n",
    "                batchnorm_classifer_bool=True,\n",
    "                dropout_classifier_bool=True)\n",
    "            optimizer_cc_aux = torch.optim.Adam(\n",
    "                model_cc_aux.parameters(), lr=lr)\n",
    "            criterion_cc_aux_main = nn.BCELoss()\n",
    "            criterion_cc_aux_aux = nn.CrossEntropyLoss()\n",
    "\n",
    "            MLP_CC_aux = MLPClassifierComparerRunnerAux(\n",
    "                model_cc_aux, [criterion_cc_aux_main,\n",
    "                               criterion_cc_aux_aux,\n",
    "                               criterion_cc_aux_aux], optimizer_cc_aux,\n",
    "                epochs, batch_size,\n",
    "                name=f'MLP_classifier_comparer_auxiliary_{i}_{hidden_size}',\n",
    "                writer_bool=tensorboard_output, verbose=verbose,\n",
    "                weights = [0.6, 0.2, 0.2])\n",
    "            CC_aux_run_output.append(MLP_CC_aux.run())\n",
    "            CC_AUX_train_losses[list_to_string(\n",
    "                hidden_size)] = MLP_CC_aux.train_loss\n",
    "            CC_AUX_test_losses[list_to_string(hidden_size)] =\\\n",
    "                MLP_CC_aux.test_loss\n",
    "            CC_AUX_train_accs[list_to_string(hidden_size)] =\\\n",
    "                MLP_CC_aux.train_acc\n",
    "            CC_AUX_test_accs[list_to_string(hidden_size)] = MLP_CC_aux.test_acc\n",
    "            CC_AUX_outputs = {\"CC_AUX_train_losses\": CC_AUX_train_losses,\n",
    "                              \"CC_AUX_test_losses\": CC_AUX_test_losses,\n",
    "                              \"CC_AUX_train_accs\": CC_AUX_train_accs,\n",
    "                              \"CC_AUX_test_accs\": CC_AUX_test_accs}\n",
    "        report_from(CC_aux_run_output,\n",
    "                    f\"MLP_classifier_comparer_auxiliary_{hidden_size}\")\n",
    "        # plot_outputs_single_network_arch(\n",
    "        #     CC_AUX_outputs,\n",
    "        #     \"MLP Classifier Comaparer Auxiliary NNs\",\n",
    "        #     \"MLP CC AUX MLP 196_\")\n",
    "\n",
    "    outputs = {}\n",
    "    outputs.update(MLP_outputs)\n",
    "    outputs.update(CC_outputs)\n",
    "    outputs.update(CC_AUX_outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e39f81-a66e-4bd0-b12c-b91ba1d59e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_widths = [200, 300, 400 ,500, 600]\n",
    "num_epochs = [200, 500, 1000]\n",
    "layers_to_check = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870d58bb-1090-4b54-8099-73adfa26d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACIES for MLP_VANILLA_[200, 196] MEAN: 0.9625, STD: 0.0045\n",
      "TEST ACCURACIES for MLP_VANILLA_[200, 196] MEAN: 0.8015, STD: 0.0141\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[300, 196] MEAN: 0.9779, STD: 0.0059\n",
      "TEST ACCURACIES for MLP_VANILLA_[300, 196] MEAN: 0.8021, STD: 0.0099\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[400, 196] MEAN: 0.9842, STD: 0.0044\n",
      "TEST ACCURACIES for MLP_VANILLA_[400, 196] MEAN: 0.8083, STD: 0.0083\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[500, 196] MEAN: 0.9899, STD: 0.0026\n",
      "TEST ACCURACIES for MLP_VANILLA_[500, 196] MEAN: 0.8041, STD: 0.0099\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[600, 196] MEAN: 0.9913, STD: 0.0032\n",
      "TEST ACCURACIES for MLP_VANILLA_[600, 196] MEAN: 0.8091, STD: 0.0100\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[200, 196] MEAN: 0.9331, STD: 0.0065\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[200, 196] MEAN: 0.8443, STD: 0.0146\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[300, 196] MEAN: 0.9495, STD: 0.0078\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[300, 196] MEAN: 0.8410, STD: 0.0118\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[400, 196] MEAN: 0.9559, STD: 0.0104\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[400, 196] MEAN: 0.8467, STD: 0.0121\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[500, 196] MEAN: 0.9694, STD: 0.0042\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[500, 196] MEAN: 0.8478, STD: 0.0100\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[600, 196] MEAN: 0.9735, STD: 0.0057\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[600, 196] MEAN: 0.8479, STD: 0.0114\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 196] MEAN: 0.9159, STD: 0.0103\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 196] MEAN: 0.8870, STD: 0.0117\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 196] MEAN: 0.9343, STD: 0.0065\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 196] MEAN: 0.8939, STD: 0.0111\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 196] MEAN: 0.9461, STD: 0.0095\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 196] MEAN: 0.8967, STD: 0.0095\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 196] MEAN: 0.9569, STD: 0.0086\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 196] MEAN: 0.8958, STD: 0.0109\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 196] MEAN: 0.9651, STD: 0.0052\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 196] MEAN: 0.8986, STD: 0.0127\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[200, 200, 196] MEAN: 0.9922, STD: 0.0024\n",
      "TEST ACCURACIES for MLP_VANILLA_[200, 200, 196] MEAN: 0.8014, STD: 0.0127\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[300, 300, 196] MEAN: 0.9941, STD: 0.0029\n",
      "TEST ACCURACIES for MLP_VANILLA_[300, 300, 196] MEAN: 0.8033, STD: 0.0120\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[400, 400, 196] MEAN: 0.9962, STD: 0.0019\n",
      "TEST ACCURACIES for MLP_VANILLA_[400, 400, 196] MEAN: 0.8008, STD: 0.0089\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[500, 500, 196] MEAN: 0.9976, STD: 0.0022\n",
      "TEST ACCURACIES for MLP_VANILLA_[500, 500, 196] MEAN: 0.8104, STD: 0.0140\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[600, 600, 196] MEAN: 0.9977, STD: 0.0024\n",
      "TEST ACCURACIES for MLP_VANILLA_[600, 600, 196] MEAN: 0.8105, STD: 0.0091\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[200, 200, 196] MEAN: 0.9655, STD: 0.0052\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[200, 200, 196] MEAN: 0.8432, STD: 0.0170\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[300, 300, 196] MEAN: 0.9805, STD: 0.0032\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[300, 300, 196] MEAN: 0.8500, STD: 0.0127\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[400, 400, 196] MEAN: 0.9853, STD: 0.0044\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[400, 400, 196] MEAN: 0.8498, STD: 0.0113\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[500, 500, 196] MEAN: 0.9891, STD: 0.0022\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[500, 500, 196] MEAN: 0.8462, STD: 0.0123\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[600, 600, 196] MEAN: 0.9920, STD: 0.0027\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[600, 600, 196] MEAN: 0.8537, STD: 0.0082\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 200, 196] MEAN: 0.9685, STD: 0.0040\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 200, 196] MEAN: 0.9302, STD: 0.0081\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 300, 196] MEAN: 0.9802, STD: 0.0041\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 300, 196] MEAN: 0.9333, STD: 0.0124\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 400, 196] MEAN: 0.9863, STD: 0.0033\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 400, 196] MEAN: 0.9348, STD: 0.0085\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 500, 196] MEAN: 0.9906, STD: 0.0025\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 500, 196] MEAN: 0.9304, STD: 0.0117\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 600, 196] MEAN: 0.9938, STD: 0.0030\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 600, 196] MEAN: 0.9386, STD: 0.0098\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[200, 200, 200, 196] MEAN: 0.9954, STD: 0.0020\n",
      "TEST ACCURACIES for MLP_VANILLA_[200, 200, 200, 196] MEAN: 0.7962, STD: 0.0191\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[300, 300, 300, 196] MEAN: 0.9977, STD: 0.0015\n",
      "TEST ACCURACIES for MLP_VANILLA_[300, 300, 300, 196] MEAN: 0.8004, STD: 0.0168\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[400, 400, 400, 196] MEAN: 0.9989, STD: 0.0007\n",
      "TEST ACCURACIES for MLP_VANILLA_[400, 400, 400, 196] MEAN: 0.8033, STD: 0.0090\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[500, 500, 500, 196] MEAN: 0.9983, STD: 0.0011\n",
      "TEST ACCURACIES for MLP_VANILLA_[500, 500, 500, 196] MEAN: 0.8071, STD: 0.0104\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_VANILLA_[600, 600, 600, 196] MEAN: 0.9995, STD: 0.0005\n",
      "TEST ACCURACIES for MLP_VANILLA_[600, 600, 600, 196] MEAN: 0.8062, STD: 0.0151\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[200, 200, 200, 196] MEAN: 0.9785, STD: 0.0053\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[200, 200, 200, 196] MEAN: 0.8410, STD: 0.0128\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[300, 300, 300, 196] MEAN: 0.9874, STD: 0.0027\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[300, 300, 300, 196] MEAN: 0.8467, STD: 0.0078\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[400, 400, 400, 196] MEAN: 0.9933, STD: 0.0021\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[400, 400, 400, 196] MEAN: 0.8497, STD: 0.0081\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[500, 500, 500, 196] MEAN: 0.9952, STD: 0.0019\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[500, 500, 500, 196] MEAN: 0.8517, STD: 0.0129\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_[600, 600, 600, 196] MEAN: 0.9961, STD: 0.0023\n",
      "TEST ACCURACIES for MLP_classifier_comparer_[600, 600, 600, 196] MEAN: 0.8562, STD: 0.0135\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 200, 200, 196] MEAN: 0.9817, STD: 0.0046\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[200, 200, 200, 196] MEAN: 0.9462, STD: 0.0077\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 300, 300, 196] MEAN: 0.9932, STD: 0.0037\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[300, 300, 300, 196] MEAN: 0.9503, STD: 0.0080\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 400, 400, 196] MEAN: 0.9959, STD: 0.0020\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[400, 400, 400, 196] MEAN: 0.9550, STD: 0.0088\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 500, 500, 196] MEAN: 0.9965, STD: 0.0020\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[500, 500, 500, 196] MEAN: 0.9550, STD: 0.0063\n",
      "\n",
      "\n",
      "TRAIN ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 600, 600, 196] MEAN: 0.9977, STD: 0.0012\n",
      "TEST ACCURACIES for MLP_classifier_comparer_auxiliary_[600, 600, 600, 196] MEAN: 0.9560, STD: 0.0085\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = {}\n",
    "for layers, epochs in zip(layers_to_check, num_epochs):\n",
    "    hidden_sizes_list = []\n",
    "    filename = f\"MLP_{layers}_LAYER_ARCHS\"\n",
    "    hidden_sizes_list = []\n",
    "    for lw in layer_widths:\n",
    "        hidden_sizes_list.append([lw] * (layers-1) + [196])\n",
    "    outputs[layers] = do_train_test(hidden_sizes_list,\n",
    "                                    epochs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518e06e2-6027-4147-ac6e-5f476897b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import report_from, Verbosity, list_to_string,\\\n",
    "#    plot_outputs_single_network_arch_from_list\n",
    "#\n",
    "#def do_plots(outputs, hidden_size_list, epochs, list_archs_for_plot, filename):\n",
    "#    print(f\"{list_archs_for_plot=}\")\n",
    "#    my_net_len = len(hidden_size_list[0])\n",
    "#    plot_outputs_single_network_arch_from_list(\n",
    "#        filename,\n",
    "#        outputs,\n",
    "#        f\"MLP Neural Networks Different Architectures with {my_net_len} Hidden Layers\",\n",
    "#        \" 196_\",\n",
    "#        epochs,\n",
    "#        list_archs_for_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2dc8fa-ec73-43f0-92ef-04e516864af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_list_list_arch_for_plot = [\n",
    "#    [[\"MLP 196_600_196\", \"CC 196_400_196\",\"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_600_600_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_600_600_600_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_500_196\", \"CC 196_400_196\", \"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_500_500_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_500_500_500_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_500_196\", \"CC 196_400_196\", \"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_500_500_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_500_500_500_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]]]\n",
    "\n",
    "\n",
    "#list_list_list_arch_for_plot = [\n",
    "#    [[\"MLP 196_600_196\", \"CC 196_400_196\",\"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_600_600_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_600_600_600_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_500_196\", \"CC 196_400_196\", \"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_500_500_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_500_500_500_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_500_196\", \"CC 196_400_196\", \"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_500_500_196\", \"CC 196_400_400_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_500_500_500_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_300_196\", \"CC 196_300_196\",\"CC_AUX 196_300_196\"],\n",
    "#     [\"MLP 196_300_300_196\", \"CC 196_300_300_196\", \"CC_AUX 196_300_300_196\"],\n",
    "#     [\"MLP 196_300_300_300_196\", \"CC 196_300_300_300_196\", \"CC_AUX 196_300_300_300_196\"]],\n",
    "#    [[\"MLP 196_400_196\", \"CC 196_400_196\",\"CC_AUX 196_400_196\"],\n",
    "#     [\"MLP 196_400_400_196\", \"CC 196_400_400_196\", \"CC_AUX 196_400_400_196\"],\n",
    "#     [\"MLP 196_400_400_400_196\", \"CC 196_400_400_400_196\", \"CC_AUX 196_400_400_400_196\"]],\n",
    "#    [[\"MLP 196_500_196\", \"CC 196_500_196\",\"CC_AUX 196_500_196\"],\n",
    "#     [\"MLP 196_500_500_196\", \"CC 196_500_500_196\", \"CC_AUX 196_500_500_196\"],\n",
    "#     [\"MLP 196_500_500_500_196\", \"CC 196_500_500_500_196\", \"CC_AUX 196_500_500_500_196\"]],\n",
    "#    [[\"MLP 196_600_196\", \"CC 196_600_196\",\"CC_AUX 196_600_196\"],\n",
    "#     [\"MLP 196_600_600_196\", \"CC 196_600_600_196\", \"CC_AUX 196_600_600_196\"],\n",
    "#     [\"MLP 196_600_600_600_196\", \"CC 196_600_600_600_196\", \"CC_AUX 196_600_600_600_196\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e89f5c9-cd6d-490a-a271-9a5275464e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, list_list_arch_for_plot in enumerate(list_list_list_arch_for_plot):\n",
    "#    for layers, epochs, list_arch_for_plot in zip(layers_to_check,\n",
    "#                                                  num_epochs,\n",
    "#                                                  list_list_arch_for_plot):\n",
    "#        hidden_sizes_list = []\n",
    "#        filename = f\"MLP_{layers}_LAYER_ARCHS\"\n",
    "#        hidden_sizes_list = []\n",
    "#        for lw in layer_widths:\n",
    "#            hidden_sizes_list.append([lw] * (layers-1) + [196])\n",
    "#        if i == 0:\n",
    "#            do_plots(outputs[layers], hidden_sizes_list,\n",
    "#                     epochs, None, filename)\n",
    "#        do_plots(outputs[layers], hidden_sizes_list,\n",
    "#                 epochs, list_arch_for_plot, filename)\n",
    "#print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa3fb7b-0be1-4027-811d-b7a5eb344afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#a_file = open(\"data_0.8_0.1_0.1.pkl\", \"wb\")\n",
    "#pickle. dump(outputs, a_file)\n",
    "#a_file. close()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5ef35-9c95-44c7-9fc4-528aadf6a828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
